import os
import sys
import torch
import numpy as np
import torch.nn as nn
from torch.utils.data import DataLoader
from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix

# --- åŠ å…¥é¡¹ç›®è·¯å¾„ ---
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

# --- å¯¼å…¥æ¨¡å— ---
from patch_loader import create_labeled_loader
from jepa.encoder import MyTimeSeriesEncoder
from jepa.predictor import JEPPredictor

# ========== åˆ†ç±»å™¨ç»“æ„ ==========
class Classifier(nn.Module):
    def __init__(self, input_dim, hidden_dim=256, output_dim=1):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(hidden_dim, output_dim)
        )
    def forward(self, x):
        return self.net(x)

# ========== é…ç½® ==========
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
MODEL_PATH = "model/jepa_best.pt"
TEST_FEATURE_PATH = "data/MSL/patches/msl_final_test.npz"
TEST_LABEL_PATH = "data/MSL/patches/msl_final_test_labels.npz"
BATCH_SIZE = 128


@torch.no_grad()
def evaluate_model(encoder, classifier, data_loader, model_name):
    print("-" * 50)
    print(f"æ­£åœ¨è¯„ä¼°: {model_name}")
    encoder.eval()
    classifier.eval()
    
    all_preds = []
    all_labels = []

    for x_batch, y_batch, x_label, y_label in data_loader:
        x_batch = x_batch.to(DEVICE)
        labels_batch = y_label.float()  # ä½¿ç”¨ç›®æ ‡åºåˆ—çš„æ ‡ç­¾

        latent = encoder(x_batch)  # shape: [B, SEQ, D]
        B, SEQ, D = latent.shape
        latent_flat = latent.reshape(B * SEQ, D)
        labels_flat = labels_batch.reshape(B * SEQ, 1).numpy()

        logits = classifier(latent_flat)  # [B*SEQ, 1]
        preds = (torch.sigmoid(logits) > 0.5).cpu().numpy()

        all_preds.append(preds)
        all_labels.append(labels_flat)

    all_preds = np.concatenate(all_preds)
    all_labels = np.concatenate(all_labels)

    # === è¯„ä¼°æŒ‡æ ‡ ===
    f1 = f1_score(all_labels, all_preds)
    precision = precision_score(all_labels, all_preds)
    recall = recall_score(all_labels, all_preds)
    cm = confusion_matrix(all_labels, all_preds)

    print(f"[{model_name}] è¯„ä¼°æŒ‡æ ‡:")
    print(f"  - F1 Score:  {f1:.4f}")
    print(f"  - Precision: {precision:.4f}")
    print(f"  - Recall:    {recall:.4f}")
    print("  - Confusion Matrix:")
    print(cm)
    print("-" * 50)


def load_pretrained_jepa(checkpoint_path: str):
    """
    åŠ è½½é¢„è®­ç»ƒçš„ JEPA æ¨¡å‹ç»„ä»¶ï¼š
    - encoder_online
    - encoder_ema (target encoder)
    - predictor
    - classifier1ï¼ˆç”¨äºpred_latentï¼‰
    - classifier2ï¼ˆç”¨äºtgt_latentï¼‰
    
    å‚æ•°:
        checkpoint_path (str): æ¨¡å‹æƒé‡æ–‡ä»¶è·¯å¾„ï¼Œä¾‹å¦‚ "model/jepa_best.pt"
    
    è¿”å›:
        Tuple[encoder_online, encoder_ema, predictor, classifier1, classifier2]
    """
    if not os.path.exists(checkpoint_path):
        raise FileNotFoundError(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {checkpoint_path}")

    print(f"ğŸ“¦ æ­£åœ¨åŠ è½½é¢„è®­ç»ƒæ¨¡å‹æƒé‡: {checkpoint_path}")
    checkpoint = torch.load(checkpoint_path, map_location=DEVICE)
    config = checkpoint['config']

    # === æ„å»º encoder é…ç½® ===
    encoder_config = {
        "patch_length": config["patch_length"],
        "num_vars": config["num_vars"],
        "latent_dim": config["latent_dim"],
        "time_layers": 2,
        "patch_layers": 3,
        "num_attention_heads": 16,
        "ffn_dim": config["latent_dim"] * 4,
        "dropout": 0.2
    }

    # === åˆå§‹åŒ–æ¨¡å‹ç»“æ„ ===
    encoder_online = MyTimeSeriesEncoder(**encoder_config).to(DEVICE)
    encoder_ema    = MyTimeSeriesEncoder(**encoder_config).to(DEVICE)
    predictor      = JEPPredictor(
        latent_dim=config["latent_dim"],
        num_layers=3,
        num_heads=16,
        ffn_dim=config["latent_dim"] * 4,
        dropout=0.2,
        prediction_length=config["prediction_length"]
    ).to(DEVICE)
    classifier1    = Classifier(input_dim=config["latent_dim"]).to(DEVICE)
    classifier2    = Classifier(input_dim=config["latent_dim"]).to(DEVICE)

    # === åŠ è½½çŠ¶æ€å­—å…¸ ===
    encoder_online.load_state_dict(checkpoint["encoder_online_state_dict"])
    encoder_ema.load_state_dict(checkpoint["encoder_ema_state_dict"])
    predictor.load_state_dict(checkpoint["predictor_state_dict"])
    classifier1.load_state_dict(checkpoint["classifier1_state_dict"])
    classifier2.load_state_dict(checkpoint["classifier2_state_dict"])

    print("âœ… æ‰€æœ‰æ¨¡å‹ç»„ä»¶åŠ è½½å®Œæ¯•ï¼")
    
    return encoder_online, encoder_ema, predictor, classifier1, classifier2


def main():
    print("æ­£åœ¨åŠ è½½æ¨¡å‹æ£€æŸ¥ç‚¹...")
    checkpoint = torch.load(MODEL_PATH, map_location=DEVICE, weights_only=True)
    
    
    config = checkpoint["config"]

    # === æå– Encoder æ‰€éœ€é…ç½® ===
    encoder_config = {
        'patch_length': config['patch_length'],
        'num_vars': config['num_vars'],
        'latent_dim': config['latent_dim'],
        'time_layers': 2,
        'patch_layers': 3,
        'num_attention_heads': 16,
        'ffn_dim': config['latent_dim'] * 4,
        'dropout': 0.2
    }

    # === åˆå§‹åŒ–æ¨¡å‹ç»“æ„ ===
    encoder_online = MyTimeSeriesEncoder(**encoder_config).to(DEVICE)
    encoder_ema = MyTimeSeriesEncoder(**encoder_config).to(DEVICE)
    classifier1 = Classifier(input_dim=config["latent_dim"]).to(DEVICE)
    classifier2 = Classifier(input_dim=config["latent_dim"]).to(DEVICE)

    # === åŠ è½½æƒé‡ ===
    print("\nğŸ“¦ æ­£åœ¨åŠ è½½æ¨¡å‹æƒé‡...")
    try:
        encoder_online.load_state_dict(checkpoint["encoder_online_state_dict"])
        print("âœ… encoder_online åŠ è½½æˆåŠŸ")
    except KeyError as e:
        print(f"âŒ encoder_online åŠ è½½å¤±è´¥: {e}")
        raise

    try:
        encoder_ema.load_state_dict(checkpoint["encoder_target_state_dict"])
        print("âœ… encoder_ema åŠ è½½æˆåŠŸ")
    except KeyError as e:
        print(f"âŒ encoder_ema åŠ è½½å¤±è´¥: {e}")
        raise

    try:
        classifier1.load_state_dict(checkpoint["classifier1_state_dict"])
        print("âœ… classifier1 åŠ è½½æˆåŠŸ")
    except KeyError as e:
        print(f"âŒ classifier1 åŠ è½½å¤±è´¥: {e}")
        raise

    try:
        classifier2.load_state_dict(checkpoint["classifier2_state_dict"])
        print("âœ… classifier2 åŠ è½½æˆåŠŸ")
    except KeyError as e:
        print(f"âŒ classifier2 åŠ è½½å¤±è´¥: {e}")
        raise

    print("\nâœ… æ‰€æœ‰æ¨¡å‹æƒé‡åŠ è½½æˆåŠŸ")

    # === åŠ è½½æµ‹è¯•é›† ===
    test_loader = create_labeled_loader(
        feature_npz_path=TEST_FEATURE_PATH,
        label_npz_path=TEST_LABEL_PATH,
        batch_size=BATCH_SIZE,
        shuffle=False
    )

    # === æ‰§è¡Œè¯„ä¼° ===
    evaluate_model(encoder_online, classifier1, test_loader, "Online Encoder + Classifier1")
    evaluate_model(encoder_ema, classifier2, test_loader, "EMA Encoder + Classifier2")


if __name__ == "__main__":
    print("ğŸš€ å¼€å§‹æµ‹è¯•é›†æ¨ç†ä¸è¯„ä¼°")
    main()
